import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

/**
 * Sends the original image and the mask to Gemini to perform inpainting/removal.
 * 
 * @param originalImageBase64 Base64 string of the original image (without data:image/png;base64, prefix if possible, but SDK handles it usually)
 * @param maskImageBase64 Base64 string of the black/white mask
 * @returns The processed image base64 string
 */
export const removeWatermark = async (
  originalImageBase64: string,
  maskImageBase64: string
): Promise<string> => {
  try {
    // Clean base64 strings if they contain headers
    const cleanOriginal = originalImageBase64.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, '');
    const cleanMask = maskImageBase64.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, '');

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image', // Mapped from "Nano Banana" as per instructions
      contents: {
        parts: [
          {
            text: "I am providing two images. The first image is the original photo. The second image is a black and white mask where white represents the area to be removed/edited. Please remove the object or watermark in the first image that corresponds to the white area in the second image. Fill the area seamlessly to match the surrounding background context. Return ONLY the resulting image."
          },
          {
            inlineData: {
              mimeType: 'image/png',
              data: cleanOriginal,
            },
          },
          {
            inlineData: {
              mimeType: 'image/png',
              data: cleanMask,
            },
          },
        ],
      },
      // Config to ensure we get an image back. 
      // Note: responseMimeType is not supported for gemini-2.5-flash-image per instructions, 
      // but the model naturally returns image parts for image generation tasks.
    });

    // Iterate through parts to find the image
    const candidates = response.candidates;
    if (candidates && candidates.length > 0) {
      const content = candidates[0].content;
      if (content.parts) {
        for (const part of content.parts) {
          if (part.inlineData && part.inlineData.data) {
            return `data:image/png;base64,${part.inlineData.data}`;
          }
        }
      }
    }

    throw new Error("No image generated by the model.");

  } catch (error) {
    console.error("Error calling Gemini API:", error);
    throw error;
  }
};